# 研究计划书

## 研究题目

基于`Parallel Corpus`使用`Reinforcement learning based Neural Machine Translation`的中国语文章阅读辅助系统。

## 研究背景

从搜索引擎到语音控制的智能音箱，机器翻译是所有现代语言处理系统的基础。最初，第一个统计性翻译系统`IBM Model 1-5代`之后，又相继出现了基于短语的`SMT`，它将文本分解成短语而非单词，通过学习词组的稳定关系，极大提高了翻译精度。然而，局限性依然很明显。如果有人基于语言学角度对数据进行干涉，那么翻译的质量会大幅下降。

而在近年大放异彩的`NMT, Neural Machine Translation`模型里，Google推出的最为典型的成功案例`BERT`，使机器翻译这一课题出现了更好的解决思路。`BERT`最大的亮点在于几乎所有NLP任务都可以套用`BERT`的`预训练-特征集成`解决思路，而效果会有明显提升。与此同时，强化学习也已经在游戏等领域取得了里程碑突破（[9, 10]）。为了解决训练阶段的 token 层面的目标函数与`BLEU`等序列层面的评估指标不一致的问题，强化学习（RL）方法已经在序列层面的目标优化上得到了应用。在`NLP`的机器翻译领域，也有相似的方法被提出（[6, 8]），所有这些研究都表明强化学习技术可以有效地用于`NMT`模型。

除此之外，谈到第二语言学习者的支援系统的等实际应用问题，以上的`RLNMT`模型也能够发挥显著作用。举个例子，即使是同一语言的母语使用者所使用的词汇、语法格式也有可能因地区、社会地位、交际场合和使用目的的不同而产生差异。对于此语言的初学者而言，这些差异就有可能造成他们的阅读障碍。虽然在帮助语言学习者的应用方面，已经有前人进行了中文作文语法纠正的研究（[1, 2]），但直到目前，仍然没有出现将上述高性能的自然语言处理方法应用在辅助初学者进行中文文章阅读方面的研究。

## **研究目的**

由研究背景部分阐述内容扩展，本人想要具体结合`Reinforcement Learning`以及`Neural machine translation`技术，就辅助初学者进行相较高难度中文文章阅读方面展开研究。希望提出的模型能够有效地在词汇与语法方面简化文章的难度，满足中文的初学者在较小的词汇量以及语法掌握度的情况下也能读懂文章的需求。

与此同时，期望研究成果能够满足以下内容：

- 在模型性能方面，希望在`SMT`的基础上提高运算效率。
- 在机器翻译方面，希望能够得到中间产物，一个具有一定词汇体量的中文同义表达方式汇预测器（`predictor`），作为日后用于缩小预测范围的有效工具。

## 先行研究

> - 关于学习支援系统[筑]，使用的方法性能（统计学方法）的限制
> - [1, 2] 前人在中文作文纠错的努力，但对于初级学习者的帮助有限（写作），研究技术有待改进（`SMT`）
> - [3 / 4 / 5] 关于`Parallel Corpus`的来源
> - [8] `RLNMT`的可行性分析，但它的单词来源对于目标句子没有针对性，在运用了`Parallel Corpus`的来源下性能能够更上一层楼（借助[9]的结论）
在外国语言的辅助学习这一应用领域，自然语言处理技术可以说是解决方法的核心手段之一。在学习阶段，能够运用机器学习方法进行辅助的功能点可以举例为阅读型、写作型、听力型、口语型等方面。作为中文的初学者而言，最难的可能就是阅读与写作这两个方面了，这就需要提出能够简化阅读，或者能够辅助写作的语言处理模型。

在写作方面，前人提出的`SMT`模型[1]与优化后的`Hierarchical phrase-based SMT`模型[2]能够完成汉语作文的语法错误诊断任务，将从`Lang-8`语言学习Blog上的文章清洗后得到的接近十万条句子作为语料库进行模型训练，在没有使用他人提供的语言资源的基础上完成了精确的错误识别任务。即使如此，由于`SMT`模型本身`Corpus`创建的时间耗费昂贵，语序不同时或者特定情况下的预测和问题解决性能难以保证的特点，模型性能仍然可能会在泛用情况下被打折扣。

在阅读方面，网络上虽然存在能够评判单词关系度与出现频率的难易度系统[11]，但其使用的统计方法仍然接近于人工统计，在数据的更新与结论的习得角度而言，其性能难免不足于当今流行的机器学习方法。同样是单词集合，则有广泛流行的`Parallel Corpus`，（有待看完文献[3/ 4/ 5]之后补充叙述内容）

而在[8]中，研究者成功地将`RLNMT`应用于实际翻译任务，提出了一种结合MLE和RL对象的新方法，在`德-英`，`英-中`，`中-英`双语数据集上进行了`RLNMT`的训练和评估，并进一步地提高使用源/目标单语数据训练的NMT系统的性能，并由此证明了`RL`方法结合`NMT`的实际可行性。但由于它的单词来源对于目标句子没有针对性，在运算效率与特定话题的表现仍然有待商榷[9]。

### 总结

- `SMT`的汉语纠正系统以及网络同义词典为第二语言初学者提供帮助的思路十分清晰，但由于`NMT`的提出，该课题方向存在性能与词汇收集效率上更好的解决方法，由此需要对过去的技术方法进行更新。
- `NMT`方法能够与`RL`进行结合，此前的学者已经提出并证明了此观点，并提出了以下结论：
  - 使用RL训练NMT模型时，该方法可以有效地利用源和目标端的大规模单语数据
  - 实践期间需要充分考虑MLE和RL对象的结合关系

按照以上的研究内容，希望能够得到能够提供汉语文章阅读辅助的`RLNMT`模型。

## 研究方法

- 训练数据收集
  - 通过[网络文章](http://www.yes-chinese.com/reading/)收集不同难度的文章，提取其中同义的`Parallel Corpus`
- 预训练
  - 基于同义`Corpus`预训练一个单词预测器
- 网络构建
  - 参照[8, 9]，结合单词预测器进行同内容低难度文章的生成，在[9]的基础上，运用`Parallel Corpus`的来源下性能能够更上一层楼
- 网络评估
  - 基于预想的替换结果句子作为评估数据，使用`BLEU`方法对模型进行评分

## 参考文献

- 1, 2：`SMT`，语言支持
- 3, 4, 5：`Corpus`
- 6, 8：`RLNMT`
- 7：`Recurrent Attention NMT`
- 9, 10：`RL`
- 