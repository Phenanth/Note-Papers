# 参考资料

## 资料来源

近义词词典推荐，[来源](https://www.zhihu.com/question/21030556/answer/133660143)

【文字】NLP发展简介，[链接](https://zhuanlan.zhihu.com/p/80093548)

分级中文阅读文章，[链接](http://www.yes-chinese.com/reading/)

【文字】强化学习做神经机器翻译（中文），[链接](https://www.jiqizhixin.com/articles/2018-09-01-4)

## 1

（概要）在2的基础上使用了`corpus-augmentation`以及`explore alternative translation models including syntax-based and hierarchical phrase-based models`

## 2

在NLP-TEA1中，我们描述了TMU系统用于完成汉语作为外语的语法错误诊断（CFL）的共享任务，CFL的语法错误校正中的主要问题之一是数据瓶颈问题。为了解决这个问题，我们从一个名为Lang-8的语言交换站点中提取了一个大型的汉语学习者语料库，该语言学习者语料库（NTNU学习者语料库）总共仅包含1,208个句子，显然不足以培训监督技术。清洗后可产生95,706个句子（两百万个单词）。我们将其用作基于短语的统计机器翻译（SMT）系统的并行语料库，该系统将学习者的句子转换为正确的句子。

> SMT的不足
>
> - Corpus创建的时间耗费昂贵
> - 特定错误难以预测和解决
> - 结果表面看起来流畅但并没有翻译出深层意思
> - 当语序不同时的表现不好
> - 由于训练语料库更小，语法差异更大，西欧语言之间的翻译所获得优异结果并不代表其他语言对的结果
>
> 在有NMT的情况下，已经不需要考虑SMT了。（然后我想起来之前的`Bayesian`...感觉之前那个要凉了哈哈）

（简介）近来，积极研究将自然语言处理技术应用于教育目的。例如，在过去的几年中，英语作为第二语言（ESL）学习者的语法错误纠正受到了广泛的关注。具体来说，ESL学习者有许多共同的语法错误纠正任务，例如“帮助我们自己”（HOO）和自然语言学习会议（CoNLL）。然而，尽管存在中文拼写错误纠正的共同任务（Wu，Liu，＆Lee，2013），但很少有人关注中文作为外语（CFL）。很难为CFL开发语法错误纠正系统的原因之一是缺乏学习者语料库。在本文中，我们提出了一种从网络中提取汉语学习者语料库的方法，并将其用于构建CFL的语法错误校正系统。本文的主要贡献如下：

- 据我们所知，这是第一部通过网络构建大规模汉语学习者语料库的作品。语料库包含100,000个句子（2,000,000个单词），并带有更正注释。
- 尽管有许多著作将基于短语的统计机器翻译（SMT）应用于中文**拼写**纠正任务，但这是第一篇将SMT应用于CFL**语法**错误纠正任务的著作。实验结果表明，本文提出的方法是建立精确的纠错系统的有效方法。
- 与先前的将基于短语的SMT用于中文拼写纠正任务的工作不同，我们建议使用逐字标记，并证明逐字（`character`）标记比逐字（`word`）标记更健壮。

（收集数据）为了缓解训练数据不足的问题，我们求助于从网络中提取中文学习者语料库。我们专注于语言交换社交网络服务（SNS），称为Lang-81。 Lang-8提供了写博客条目时可以使用的多种语言。资深用户逐句纠正以您的学习语言编写的博客条目，而您又可以纠正其他语言以母语编写的博客条目。语言8促进了相互“语言交换”的过程。截止到目前（2014年8月），Lang-8拥有约100万用户，其中50,000是中国学习者。

（总结）在本文中，我们描述了NMU-TEA1上用于CFL共享任务语法错误诊断的TMU系统。为了增加训练语料库的数量，我们探索了用于构建中文学习者语料库的网络。我们从语言交换SNS Lang-8中提取了100,000个学习者语料库，并将其用于训练基于SMT的语法错误纠正系统。尽管系统没有使用共享任务组织者提供的任何语言资源，但是它执行了精确的错误识别。

## 8

（概要）最近的研究表明，强化学习（RL）是一种有效的改进神经机器翻译（NMT）系统的性能的方法
但是，由于其不稳定性，成功地进行RL培训非常有挑战性，尤其是在利用了深层模型和大型数据集的真实系统中。本文以几个大型翻译任务为测试平台，对如何通过强化学习来训练更好的NMT模型进行了系统的研究。我们提供了RL培训中几个重要因素（例如，基线奖励，奖励塑造）的综合比较。此外，为了填补尚不清楚使用单语数据时RL是否仍然有益的空白，我们提出了一种利用RL的新方法，以进一步提高使用源/目标单语数据训练的NMT系统的性能。通过整合所有发现，我们在WMT14英语-德语，WMT17英语- 中文和WMT17中英文翻译任务，尤其是设置WMT17中英文翻译任务的最新性能。

（介绍）通常，通过将源句子和前面的（真实的）目标标记作为输入，对它进行训练，以使目标句子中每个标记的可能性最大化。这种训练方法称为最大似然估计（`MLE`）。尽管易于实现，但训练过程中的令牌级目标功能与序列级评估指标（例如BLEU）不一致。为解决上述不一致问题，增强学习（RL）方法已被用来优化序列级目标。例如，策略优化方法（例如`REINFORCE`和`actorcritic`）可用于包括`NMT`在内的序列生成（`sequence generation`）任务。在机器翻译领域，相同的方法则被称作为`minimum risk traning`。

但是，以前的工作尚未实现将RL有效地应用于实际NMT系统。首先，大多数以前的工作基于浅层递归神经网络（RNN）模型验证了他们的方法。但是，要获得最先进的（`SOTA, state-of-the-art`）性能，必须利用功能强大得多的最新衍生的深度模型。其次，鉴于RL方法存在许多公认的局限性，例如梯度估计的高方差和目标不稳定性，要使RL切实有效并不容易，因此，在先前的工作中提出了一些技巧。但是，目前尚不清楚，在如何在机器翻译中使用这些技巧方面还没有达成共识。例如有的人推荐使用`Baseline Reward Method`，而有些人不这样认为。第三，大规模数据集，尤其是单语种数据集显示出通过MLE训练显着提高了翻译质量，而**在NMT中如何将RL与单语种数据结合起来**却几乎空白。

在本文中，我们试图弥补这些差距，并研究如何实际应用RL来获得功能强大，富有竞争力，甚至足够优雅（`SOTA`）的NMT系统。针对RL培训的不同方面进行了几项综合研究，以找出如何：

1. 设定有效的奖励；
2. 结合不同权重的MLE和RL对象，以稳定训练过程；
3. 减少梯度估计的方差。

此外，鉴于利用单语数据提高翻译质量的有效性，我们进一步提出了一种结合RL训练和源/目标单语数据强度的新方法。据我们所知，这是第一个尝试探索使用RL方法训练NMT模型时单语数据的功能的工作。通过对WMT17汉英（Zh-En），WMT17汉英（En-Zh）和WMT14英德（En-De）翻译任务的实验，我们获得了一些有用的发现。例如，在奖励计算中，多项式抽样比波束搜索更好，并且RL和单语数据的组合显着增强了NMT模型的性能。我们的主要贡献概述如下。

- 除了竞争激烈的NMT模型之外，我们还提供了有关RL培训各个方面的首次综合研究，例如如何设置奖励和基准奖励。
- 我们提出一种新方法，当使用RL训练NMT模型时，该方法可以有效地利用源和目标端的大规模单语数据
- 结合我们的一些发现和方法，我们在WMT17 Zh-En翻译任务获得了SOTA的翻译质量，比`strong baseline`（Transformer大模型+反向翻译）高出将近1.5 BLEU点。此外，在WMT14 En-De和WMT17 En-Zh的翻译任务上，我们还可以获得强大的竞争成果。

我们希望我们的研究和发现将使社区受益，以更好地理解和利用强化学习来开发强大的NMT模型，尤其是在面对深度模型和大量培训数据（包括并行和单语言数据）的现实世界中。

> [开源代码](https://github.com/apeterswu/RL4NMT)

（结论）使用`德-英`，`英-中`，`中-英`双语数据集进行了`RLNMT`的训练和评估。结论有：

1. 多项式采样比波束搜索更好
2. 先前的一些技巧，例如奖励塑造和基线奖励，并没有太大的不同
3. MLE和RL目标的结合很重要

另外，我们探索了用于RL培训的源/目标单语数据。通过结合RL和单语数据的强大功能，我们在WMT17中文-英语翻译任务上获得了最新的BLEU评分。我们希望我们的研究和结果可以使社区受益，并带来一些有关如何通过强化学习和大数据来训练深度NMT模型的见解。